"""
æœ¬æ—¥æ¤œæŸ»å“ ä¸å…·åˆåˆ†æãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰è‡ªå‹•ç”Ÿæˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ

è¦ä»¶å®šç¾©æ›¸_defect_dashboard_generator.md ã«åŸºã¥ãå®Ÿè£…ã€‚
2ã¤ã®Access DBï¼ˆå¤–è¦³æ¤œæŸ»é›†è¨ˆ / ä¸å…·åˆæƒ…å ±ï¼‰ã‹ã‚‰æœ¬æ—¥å¯¾è±¡ãƒ­ãƒƒãƒˆã®ä¸å…·åˆã‚’é›†è¨ˆã—ã€
éå»3å¹´ã®æ¨ç§»ã¨åˆã‚ã›ã¦SaaSé¢¨HTMLãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã‚’ç”Ÿæˆã™ã‚‹ã€‚
"""

from __future__ import annotations

import argparse
import json
import logging
import os
import warnings
from dataclasses import dataclass
from datetime import datetime, timedelta, date
from pathlib import Path
from typing import Iterable, Optional, Tuple, List, Dict
import re

import pandas as pd
import pyodbc
try:
    from jinja2 import Environment, FileSystemLoader, Template
except ImportError as e:  # pragma: no cover
    raise ImportError(
        "jinja2 ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚requirements.txt ã«è¿½è¨˜æ¸ˆã¿ã§ã™ã€‚"
        " `pip install -r requirements.txt` ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚"
    ) from e

try:
    import google.generativeai as genai
except ImportError:  # pragma: no cover
    genai = None

try:
    from dotenv import load_dotenv
except ImportError:  # pragma: no cover
    load_dotenv = None

# Gemini ã‚¯ã‚©ãƒ¼ã‚¿è¶…éæ™‚ã«ä»¥é™ã®å‘¼ã³å‡ºã—ã‚’æ­¢ã‚ã‚‹ãŸã‚ã®ãƒ•ãƒ©ã‚°
_GEMINI_QUOTA_EXCEEDED = False


# -----------------------------
# è¨­å®š
# -----------------------------

@dataclass
class Config:
    appearance_db_path: str = r"\\192.168.1.200\å…±æœ‰\å“è³ªä¿è¨¼èª²\å¤–è¦³æ¤œæŸ»è¨˜éŒ²\å¤–è¦³æ¤œæŸ»è¨˜éŒ²ç…§ä¼š.accdb"
    appearance_table: str = "t_å¤–è¦³æ¤œæŸ»é›†è¨ˆ"
    defect_db_path: str = r"\\192.168.1.200\å…±æœ‰\å“è³ªä¿è¨¼èª²\å¤–è¦³æ¤œæŸ»è¨˜éŒ²\ä¸å…·åˆæƒ…å ±è¨˜éŒ².accdb"
    defect_table: str = "t_ä¸å…·åˆæƒ…å ±"
    output_dir: str = "."
    template_path: Optional[str] = None  # æŒ‡å®šãŒã‚ã‚Œã°å¤–éƒ¨HTMLãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’åˆ©ç”¨
    logo_text: str = "ARAI"


DEFAULT_IGNORE_COLUMNS = {
    "ç”Ÿç”£ãƒ­ãƒƒãƒˆID", "æŒ‡ç¤ºæ—¥", "æ¤œæŸ»æ—¥", "æ—¥ä»˜", "æ¤œæŸ»æ—¥ä»˜", "å“ç•ª", "å“å", "å·¥ç¨‹NO", "å·¥ç¨‹", "å·æ©Ÿ", "æ™‚é–“",
    "æ•°é‡", "ç·ä¸å…·åˆæ•°", "ä¸è‰¯ç‡",
}

FIXED_WORST_41ST_HINBANS = [
    "08121-26312A",
    "08121-26322A",
    "A41G1CA302",
    "20002100001-N",
    "06131-01710R",
    "06113-01310S",
    "FC00-1401-4",
    "MA1005-0518003",
    "06081-03911K",
    "H115A201G001-N",
    "4C-2205B",
]

FIXED_WORST_41ST_INFO: Dict[str, Dict[str, str]] = {
    "08121-26312A": {"å“å": "ï¾ï¾ï¾€ï½²", "å®¢å…ˆå": "ä¸äºŒãƒ—ãƒ¬ã‚·ã‚¸ãƒ§ãƒ³", "ä¸»ãªä¸å…·åˆ": "æºãƒ»å†…å¾„å¯¸æ³•ã€å¤–å¾„ãƒ»ç«¯é¢å‚·"},
    "08121-26322A": {"å“å": "ï¾ï¾ï¾€ï½²", "å®¢å…ˆå": "ä¸äºŒãƒ—ãƒ¬ã‚·ã‚¸ãƒ§ãƒ³", "ä¸»ãªä¸å…·åˆ": "æºãƒ»å†…å¾„å¯¸æ³•ã€å¤–å¾„ãƒ»ç«¯é¢å‚·"},
    "A41G1CA302": {"å“å": "ï½¸ï¾›ï½½ï¾Šï¾ï½°", "å®¢å…ˆå": "ä½å‹é‡æ©Ÿæ¢°å·¥æ¥­", "ä¸»ãªä¸å…·åˆ": "å†…å¾„å¯¸æ³•ã€åœ§ç—•"},
    "20002100001-N": {"å“å": "ï¾ï¾ï½±ï¾˜ï¾ï½¸ï¾å—ã‘C", "å®¢å…ˆå": "ãƒŠã‚«ãƒ‹ã‚·", "ä¸»ãªä¸å…·åˆ": "å…¨é•·ä¸è‰¯ã€å‚·ã€æ‰“ç—•ã€æŒ½ç›®"},
    "06131-01710R": {"å“å": "ï¾Œï¾Ÿï¾—ï¾ï½¼ï¾ï½¬", "å®¢å…ˆå": "ä¸äºŒãƒ†ã‚¯ãƒã‚¹", "ä¸»ãªä¸å…·åˆ": "å†…å¾„ä¸è‰¯ã€å‚·ã€ãƒãƒªã€ãƒ ã‚·ãƒ¬"},
    "06113-01310S": {"å“å": "ï¾ï¾™ï¾€ï¾", "å®¢å…ˆå": "ä¸äºŒãƒ†ã‚¯ãƒã‚¹", "ä¸»ãªä¸å…·åˆ": "å…¨é•·ãƒ»å†…å¾„å¯¸æ³•ã€å‚·ã€ãƒ ã‚·ãƒ¬"},
    "FC00-1401-4": {"å“å": "æµé‡èª¿æ•´ï¾•ï¾†ï½¯ï¾„æœ¬ä½“", "å®¢å…ˆå": "ãƒã‚·ãƒ€æŠ€ç ”å·¥æ¥­", "ä¸»ãªä¸å…·åˆ": "å‚·ã€æ‰“ç—•ã€åå¿ƒéƒ¨ãƒ ã‚·ãƒ¬"},
    "MA1005-0518003": {"å“å": "ï¾ï¾ï½±ï¾˜ï¾ï½¸ï¾å—ã‘J", "å®¢å…ˆå": "ãƒŠã‚«ãƒ‹ã‚·", "ä¸»ãªä¸å…·åˆ": "å†…ãƒ»å¤–å¾„å¯¸æ³•ã€å‚·ã€æ‰“ç—•"},
    "06081-03911K": {"å“å": "ï½·ï½­ï½³ï½²ï¾ï½¼", "å®¢å…ˆå": "ä¸äºŒãƒ†ã‚¯ãƒã‚¹", "ä¸»ãªä¸å…·åˆ": "å†…ãƒ»å¤–å¾„å¯¸æ³•ã€å‚·ã€ãƒãƒªã€ï¾‘ï½¼ï¾š"},
    "H115A201G001-N": {"å“å": "ï¾‰ï½°ï½½ï¾", "å®¢å…ˆå": "ãƒŠã‚«ãƒ‹ã‚·", "ä¸»ãªä¸å…·åˆ": "å†…å¾„å¯¸æ³•"},
    "4C-2205B": {"å“å": "ï½´ï¾ï¾„ï¾", "å®¢å…ˆå": "UEK", "ä¸»ãªä¸å…·åˆ": "å†…å¾„ãƒ»ï¾ˆï½¼ï¾ã€æ‰“ç—•ã€æŒ½ç›®ã€ï¾‘ï½¼ï¾š"},
}

# ARAIãƒ­ã‚´ï¼ˆOutlook-æ ªå¼ä¼šç¤¾ æ–°äº•ç²¾å¯†.png ã‚’base64åŸ‹ã‚è¾¼ã¿ï¼‰
LOGO_BASE64 = (
    "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"
)


# -----------------------------
# æœŸåˆ¤å®š & Gemini
# -----------------------------

FIRST_TERM_NUMBER = 41
FIRST_TERM_START = date(2024, 10, 1)
FISCAL_YEAR_MONTHS = 12


@dataclass
class TermInfo:
    term_number: int
    start_date: date
    end_date: date


def get_term_info(target_date: date) -> TermInfo:
    months_diff = (target_date.year - FIRST_TERM_START.year) * 12 + (
        target_date.month - FIRST_TERM_START.month
    )
    term_offset = months_diff // FISCAL_YEAR_MONTHS
    term_number = FIRST_TERM_NUMBER + term_offset
    start_year = FIRST_TERM_START.year + term_offset
    start_date = date(start_year, FIRST_TERM_START.month, FIRST_TERM_START.day)
    end_date = date(start_year + 1, FIRST_TERM_START.month, FIRST_TERM_START.day) - timedelta(days=1)
    return TermInfo(term_number=term_number, start_date=start_date, end_date=end_date)


def get_previous_term_info(target_date: date) -> TermInfo:
    current = get_term_info(target_date)
    prev_start_year = current.start_date.year - 1
    prev_start = date(prev_start_year, FIRST_TERM_START.month, FIRST_TERM_START.day)
    prev_end = current.start_date - timedelta(days=1)
    prev_term_number = current.term_number - 1
    return TermInfo(term_number=prev_term_number, start_date=prev_start, end_date=prev_end)


def configure_gemini() -> None:
    if genai is None:
        raise RuntimeError("google-generativeai ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
    api_key = os.environ.get("GEMINI_API_KEY")
    if not api_key:
        raise RuntimeError("ç’°å¢ƒå¤‰æ•° GEMINI_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
    genai.configure(api_key=api_key)


def build_worst_part_prompt_for_term(
    term_info: TermInfo,
    part_number: str,
    part_name: str,
    customer: str,
    major_defects: str,
    trend_table: str,
    defect_kind_summary: str,
    today_qty: int,
    today_ng: int,
    today_rate: float,
    today_defect_kinds: str,
) -> str:
    term_label = f"{term_info.term_number}æœŸï¼ˆ{term_info.start_date:%Y/%m/%d}ã€œ{term_info.end_date:%Y/%m/%d}ï¼‰"
    worst_label = f"{term_info.term_number}æœŸãƒ¯ãƒ¼ã‚¹ãƒˆå“ç•ª"
    return f"""
ä»¥ä¸‹ã¯ã€å½“ç¤¾ï¼ˆç²¾å¯†åŠ å·¥éƒ¨å“ãƒ¡ãƒ¼ã‚«ãƒ¼ï¼‰ã«ãŠã‘ã‚‹ã€Œ{worst_label}ã€ã®
éå»3å¹´ãƒ‡ãƒ¼ã‚¿ã¨æœ¬æ—¥ã®ä¸å…·åˆãƒ‡ãƒ¼ã‚¿ã§ã™ã€‚ï¼ˆå¯¾è±¡æœŸ: {term_label}ï¼‰

ç›®çš„ï¼šè£½é€ ãŒã™ãè¡Œå‹•ã§ãã‚‹ **çŸ­ãè¦ç‚¹ã ã‘ã®ã‚³ãƒ¡ãƒ³ãƒˆ** ã‚’ä½œã‚‹ã“ã¨ã€‚
å¿…ãš **3ã€œ6è¡Œä»¥å†…** ã«ã¾ã¨ã‚ã‚‹ã“ã¨ã€‚é•·æ–‡ã¯ç¦æ­¢ã€‚

---
ã€å¯¾è±¡ã€‘
å“ç•ª: {part_number}
å“å: {part_name}
å®¢å…ˆ: {customer}
ä¸»ãªä¸å…·åˆ: {major_defects}

ã€éå»3å¹´ã®å‚¾å‘ã€‘
{trend_table}

ã€ä¸å…·åˆåŒºåˆ†ã‚µãƒãƒªã€‘
{defect_kind_summary}

ã€æœ¬æ—¥ã®ä¸å…·åˆã€‘
æ¤œæŸ»æ•°={today_qty}, ä¸è‰¯æ•°={today_ng}, ä¸è‰¯ç‡={today_rate:.2f}%
æœ¬æ—¥ã®ä¸å…·åˆ: {today_defect_kinds}
---

ä»¥ä¸‹ã®å½¢å¼ã§ç°¡æ½”ã«ã¾ã¨ã‚ã¦ãã ã•ã„ï¼š

â‘  ä»Šæ—¥ã®å“è³ªçŠ¶æ…‹ã®ä¸€è¨€è©•ä¾¡  
â‘¡ éå»å‚¾å‘ã¨ç…§ã‚‰ã—ã¦ã€Œå¶ç™ºã‹å†ç™ºå…†å€™ã‹ã€ã®åˆ¤æ–­  
â‘¢ è£½é€ ãŒä»Šæ—¥ã™ãå®Ÿæ–½ã™ã¹ãå¯¾ç­–ã‚’ 1ã€œ2 è¡Œ

â€» æ–‡ç« ã¯ **å¿…ãš3ã€œ6è¡Œä»¥å†…**
â€» è©³ã—ã„ç†å±ˆã‚„é•·ã„èª¬æ˜ã¯ç¦æ­¢
â€» èª­ã¿æ‰‹ãŒè¿·ã‚ãšç†è§£ã§ãã‚‹è¡¨ç¾ã«ã™ã‚‹ã“ã¨
""".strip()


def generate_worst_part_comment(prompt: str, model_name: Optional[str] = None) -> str:
    if genai is None:
        return ""
    global _GEMINI_QUOTA_EXCEEDED
    if _GEMINI_QUOTA_EXCEEDED:
        return ""

    # ãƒ¢ãƒ‡ãƒ«åã¯ç’°å¢ƒå¤‰æ•° GEMINI_MODEL ã§ä¸Šæ›¸ãå¯èƒ½ã€‚å­˜åœ¨ã—ãªã„å ´åˆã«å‚™ãˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã™ã‚‹ã€‚
    candidates = [
        model_name,
        os.environ.get("GEMINI_MODEL"),
        "gemini-1.5-pro-latest",
        "gemini-1.5-flash-latest",
        "gemini-2.0-flash",
    ]
    last_err: Optional[Exception] = None
    for name in [c for c in candidates if c]:
        try:
            model = genai.GenerativeModel(name)
            response = model.generate_content(prompt)
            return (response.text or "").strip()
        except Exception as e:  # pragma: no cover
            msg = str(e)
            if "429" in msg or "quota" in msg.lower() or "rate limit" in msg.lower():
                _GEMINI_QUOTA_EXCEEDED = True
                return ""
            last_err = e
            continue
    if last_err:
        raise last_err
    return ""


def build_general_part_prompt(
    part_number: str,
    part_name: str,
    customer: str,
    trend_table: str,
    defect_kind_summary: str,
    today_qty: int,
    today_ng: int,
    today_rate: float,
    today_defect_kinds: str,
) -> str:
    return f"""
ä»¥ä¸‹ã¯ã€å½“ç¤¾ï¼ˆç²¾å¯†åŠ å·¥éƒ¨å“ãƒ¡ãƒ¼ã‚«ãƒ¼ï¼‰ã«ãŠã‘ã‚‹å¯¾è±¡å“ç•ªã®
éå»3å¹´ãƒ‡ãƒ¼ã‚¿ã¨æœ¬æ—¥ã®ä¸å…·åˆãƒ‡ãƒ¼ã‚¿ã§ã™ã€‚

ç›®çš„ï¼šè£½é€ ãŒã™ãè¡Œå‹•ã§ãã‚‹ **çŸ­ãè¦ç‚¹ã ã‘ã®ã‚³ãƒ¡ãƒ³ãƒˆ** ã‚’ä½œã‚‹ã“ã¨ã€‚
å¿…ãš **3ã€œ6è¡Œä»¥å†…** ã«ã¾ã¨ã‚ã‚‹ã“ã¨ã€‚é•·æ–‡ã¯ç¦æ­¢ã€‚

---
ã€å¯¾è±¡ã€‘
å“ç•ª: {part_number}
å“å: {part_name}
å®¢å…ˆ: {customer}

ã€éå»3å¹´ã®å‚¾å‘ã€‘
{trend_table}

ã€ä¸å…·åˆåŒºåˆ†ã‚µãƒãƒªã€‘
{defect_kind_summary}

ã€æœ¬æ—¥ã®ä¸å…·åˆã€‘
æ¤œæŸ»æ•°={today_qty}, ä¸è‰¯æ•°={today_ng}, ä¸è‰¯ç‡={today_rate:.2f}%
æœ¬æ—¥ã®ä¸å…·åˆ: {today_defect_kinds}
---

ä»¥ä¸‹ã®å½¢å¼ã§ç°¡æ½”ã«ã¾ã¨ã‚ã¦ãã ã•ã„ï¼š

â‘  ä»Šæ—¥ã®å“è³ªçŠ¶æ…‹ã®ä¸€è¨€è©•ä¾¡  
â‘¡ éå»å‚¾å‘ã¨ç…§ã‚‰ã—ã¦ã€Œå¶ç™ºã‹å†ç™ºå…†å€™ã‹ã€ã®åˆ¤æ–­  
â‘¢ è£½é€ ãŒä»Šæ—¥ã™ãå®Ÿæ–½ã™ã¹ãå¯¾ç­–ã‚’ 1ã€œ2 è¡Œ

â€» æ–‡ç« ã¯ **å¿…ãš3ã€œ6è¡Œä»¥å†…**
â€» è©³ã—ã„ç†å±ˆã‚„é•·ã„èª¬æ˜ã¯ç¦æ­¢
â€» èª­ã¿æ‰‹ãŒè¿·ã‚ãšç†è§£ã§ãã‚‹è¡¨ç¾ã«ã™ã‚‹ã“ã¨
""".strip()

def load_config(path: Optional[str]) -> Config:
    if not path:
        return Config()
    p = Path(path)
    if not p.exists():
        raise FileNotFoundError(f"config file not found: {p}")
    data = json.loads(p.read_text(encoding="utf-8"))
    cfg = Config()
    for k, v in data.items():
        if hasattr(cfg, k):
            setattr(cfg, k, v)
    return cfg


def setup_logging(output_dir: str) -> None:
    Path(output_dir).mkdir(parents=True, exist_ok=True)
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s %(levelname)s %(message)s",
        handlers=[logging.StreamHandler()],
    )


# -----------------------------
# Access èª­ã¿è¾¼ã¿
# -----------------------------

def connect_access(db_path: str):
    conn_str = (
        r"Driver={Microsoft Access Driver (*.mdb, *.accdb)};"
        rf"DBQ={db_path};"
        r"ReadOnly=1;"
    )
    return pyodbc.connect(conn_str)


def read_access_table(db_path: str, table: str) -> pd.DataFrame:
    logging.info("reading Access table %s from %s", table, db_path)
    with connect_access(db_path) as conn:
        with warnings.catch_warnings():
            warnings.filterwarnings(
                "ignore",
                message="pandas only supports SQLAlchemy connectable*",
                category=UserWarning,
            )
            return pd.read_sql(f"SELECT * FROM {table}", conn)


def read_product_master(db_path: str) -> pd.DataFrame:
    table = "t_è£½å“ãƒã‚¹ã‚¿"
    try:
        df = read_access_table(db_path, table)
    except Exception as e:
        logging.warning("failed to read product master %s: %s", table, e)
        return pd.DataFrame()
    needed = {"è£½å“ç•ªå·", "è£½å“å", "å®¢å…ˆå"}
    if not needed.issubset(set(df.columns)):
        logging.warning("product master missing columns: %s", needed - set(df.columns))
        return pd.DataFrame()
    return df[list(needed)].drop_duplicates(subset=["è£½å“ç•ªå·"])


# -----------------------------
# ãƒ‡ãƒ¼ã‚¿æ•´å½¢ãƒ»æŠ½å‡º
# -----------------------------

def find_date_column(df: pd.DataFrame) -> Optional[str]:
    candidates = ["æŒ‡ç¤ºæ—¥", "æ¤œæŸ»æ—¥", "æ¤œæŸ»æ—¥ä»˜", "æ—¥ä»˜", "å®Ÿæ–½æ—¥", "ä½œæˆæ—¥"]
    for c in candidates:
        if c in df.columns:
            return c
    # datetimeå‹ã‚‰ã—ã„åˆ—ã‚’ãƒ’ãƒ¥ãƒ¼ãƒªã‚¹ãƒ†ã‚£ãƒƒã‚¯ã«æ¢ã™
    for c in df.columns:
        if "æ—¥" in c and df[c].dtype != object:
            return c
    return None


def normalize_dates(df: pd.DataFrame, col: Optional[str]) -> pd.DataFrame:
    if not col:
        return df
    df = df.copy()
    df[col] = pd.to_datetime(df[col], errors="coerce")
    return df


def extract_today_lots(appearance_df: pd.DataFrame, run_date: datetime) -> pd.DataFrame:
    date_col = find_date_column(appearance_df)
    appearance_df = normalize_dates(appearance_df, date_col)

    if date_col:
        today_mask = appearance_df[date_col].dt.date == run_date.date()
        today_df = appearance_df.loc[today_mask].copy()
        logging.info("appearance rows for today: %s", len(today_df))
    else:
        today_df = appearance_df.copy()
        logging.warning("no date column in appearance table; using all rows")

    if "ç”Ÿç”£ãƒ­ãƒƒãƒˆID" not in today_df.columns:
        raise KeyError("appearance table must include ç”Ÿç”£ãƒ­ãƒƒãƒˆID")
    return today_df


def join_defects(today_lots_df: pd.DataFrame, defect_df: pd.DataFrame) -> pd.DataFrame:
    if "ç”Ÿç”£ãƒ­ãƒƒãƒˆID" not in defect_df.columns:
        raise KeyError("defect table must include ç”Ÿç”£ãƒ­ãƒƒãƒˆID")
    lots = today_lots_df["ç”Ÿç”£ãƒ­ãƒƒãƒˆID"].dropna().astype(str).unique().tolist()
    defect_df = defect_df.copy()
    defect_df["ç”Ÿç”£ãƒ­ãƒƒãƒˆID"] = defect_df["ç”Ÿç”£ãƒ­ãƒƒãƒˆID"].astype(str)
    joined = defect_df[defect_df["ç”Ÿç”£ãƒ­ãƒƒãƒˆID"].isin(lots)].copy()
    # ä¸å…·åˆå´ã«å·æ©ŸãŒç„¡ã„å ´åˆã€å¤–è¦³å´ã‹ã‚‰ä»˜ä¸
    if "å·æ©Ÿ" not in joined.columns and "å·æ©Ÿ" in today_lots_df.columns:
        joined = joined.merge(
            today_lots_df[["ç”Ÿç”£ãƒ­ãƒƒãƒˆID", "å·æ©Ÿ"]],
            on="ç”Ÿç”£ãƒ­ãƒƒãƒˆID",
            how="left",
        )
    logging.info("defect rows for today lots: %s", len(joined))
    return joined


def detect_defect_columns(df: pd.DataFrame) -> List[str]:
    cols: List[str] = []
    for c in df.columns:
        if c in DEFAULT_IGNORE_COLUMNS:
            continue
        if re.match(r"^ID\d+", str(c)) or str(c).startswith("ID"):
            continue
        if pd.api.types.is_numeric_dtype(df[c]):
            cols.append(c)
    if not cols and "ç·ä¸å…·åˆæ•°" in df.columns:
        cols = ["ç·ä¸å…·åˆæ•°"]
    return cols


def _summarize_defect_breakdown_row(row: pd.Series, defect_cols: List[str]) -> str:
    parts: List[str] = []
    for c in defect_cols:
        v = row.get(c, 0)
        try:
            if pd.isna(v) or float(v) <= 0:
                continue
        except Exception:
            continue
        parts.append(f"{c}{int(v)}")
    return "ã€".join(parts) if parts else "-"


def compute_today_summary(today_lots_df: pd.DataFrame, today_defects_df: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame]:
    if "å“ç•ª" not in today_defects_df.columns and "å“ç•ª" not in today_lots_df.columns:
        raise KeyError("å“ç•ª column not found in either table")

    key_col = "å“ç•ª" if "å“ç•ª" in today_defects_df.columns else "å“ç•ª"
    group_keys: List[str] = [key_col]
    if "å·æ©Ÿ" in today_lots_df.columns or "å·æ©Ÿ" in today_defects_df.columns:
        group_keys.append("å·æ©Ÿ")
    defect_cols = detect_defect_columns(today_defects_df)

    # æ•°é‡ã¯å¤–è¦³å´ï¼ˆã‚ã‚Œã°ï¼‰â†’ä¸å…·åˆå´ã¸ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    qty_col = "æ•°é‡" if "æ•°é‡" in today_lots_df.columns else ("æ•°é‡" if "æ•°é‡" in today_defects_df.columns else None)
    if qty_col:
        if set(group_keys).issubset(set(today_lots_df.columns)):
            qty_by_hinban = today_lots_df.groupby(group_keys, as_index=False)[qty_col].sum()
        else:
            qty_by_hinban = today_defects_df.groupby(group_keys, as_index=False)[qty_col].sum()
    else:
        qty_by_hinban = today_defects_df[group_keys].drop_duplicates()
        qty_by_hinban["æ•°é‡"] = 0

    if "ç·ä¸å…·åˆæ•°" in today_defects_df.columns:
        total_def_by_hinban = today_defects_df.groupby(group_keys, as_index=False)["ç·ä¸å…·åˆæ•°"].sum()
    else:
        total_def_by_hinban = today_defects_df.groupby(group_keys, as_index=False)[defect_cols].sum()
        total_def_by_hinban["ç·ä¸å…·åˆæ•°"] = total_def_by_hinban[defect_cols].sum(axis=1)
        total_def_by_hinban = total_def_by_hinban[group_keys + ["ç·ä¸å…·åˆæ•°"]]

    summary = qty_by_hinban.merge(total_def_by_hinban, on=group_keys, how="outer").fillna(0)
    summary["ä¸è‰¯ç‡"] = summary.apply(
        lambda r: (r["ç·ä¸å…·åˆæ•°"] / r[qty_col]) if qty_col and r[qty_col] else 0.0,
        axis=1,
    )
    summary = summary.sort_values("ä¸è‰¯ç‡", ascending=False).reset_index(drop=True)

    # åŒºåˆ†åˆ¥é›†è¨ˆï¼ˆè¦‹ã‚„ã™ã•é‡è¦–ã§1åˆ—ã«ã¾ã¨ã‚ã‚‹ï¼‰
    if defect_cols:
        defects_breakdown = today_defects_df.groupby(group_keys, as_index=False)[defect_cols].sum()
        defects_breakdown["ä¸å…·åˆå†…è¨³"] = defects_breakdown.apply(
            lambda r: _summarize_defect_breakdown_row(r, defect_cols),
            axis=1,
        )
        defects_breakdown = defects_breakdown[group_keys + ["ä¸å…·åˆå†…è¨³"]]
    else:
        defects_breakdown = pd.DataFrame(columns=group_keys + ["ä¸å…·åˆå†…è¨³"])

    # ã‚µãƒãƒªãƒ¼ã«å†…è¨³ã‚’çµ±åˆ
    summary = summary.merge(defects_breakdown, on=group_keys, how="left")
    summary["ä¸å…·åˆå†…è¨³"] = summary["ä¸å…·åˆå†…è¨³"].fillna("-")

    return summary, defects_breakdown


def filter_last_3years(defect_df: pd.DataFrame, run_date: datetime) -> pd.DataFrame:
    date_col = find_date_column(defect_df)
    defect_df = normalize_dates(defect_df, date_col)
    if not date_col:
        logging.warning("no date column in defect table; using all rows for 3-year stats")
        return defect_df
    cutoff = run_date - timedelta(days=365 * 3)
    return defect_df.loc[defect_df[date_col] >= cutoff].copy()


def compute_worst_hinban(defects_3y: pd.DataFrame) -> Optional[str]:
    if "å“ç•ª" not in defects_3y.columns:
        return None
    qty_col = "æ•°é‡" if "æ•°é‡" in defects_3y.columns else None
    if "ç·ä¸å…·åˆæ•°" in defects_3y.columns:
        g = defects_3y.groupby("å“ç•ª", as_index=False).agg({"ç·ä¸å…·åˆæ•°": "sum", **({qty_col: "sum"} if qty_col else {})})
        if qty_col:
            g["ä¸è‰¯ç‡"] = g["ç·ä¸å…·åˆæ•°"] / g[qty_col].replace(0, pd.NA)
        else:
            g["ä¸è‰¯ç‡"] = g["ç·ä¸å…·åˆæ•°"]
    else:
        defect_cols = detect_defect_columns(defects_3y)
        g = defects_3y.groupby("å“ç•ª", as_index=False)[defect_cols].sum()
        g["ç·ä¸å…·åˆæ•°"] = g[defect_cols].sum(axis=1)
        g["ä¸è‰¯ç‡"] = g["ç·ä¸å…·åˆæ•°"]
    g = g.sort_values("ä¸è‰¯ç‡", ascending=False)
    return g.iloc[0]["å“ç•ª"] if len(g) else None


def aggregate_trends(defects_3y: pd.DataFrame, target_hinbans: List[str], run_date: datetime) -> Tuple[pd.DataFrame, pd.DataFrame]:
    if "å“ç•ª" not in defects_3y.columns:
        return pd.DataFrame(), pd.DataFrame()

    date_col = find_date_column(defects_3y)
    defects_3y = normalize_dates(defects_3y, date_col)
    if not date_col:
        return pd.DataFrame(), pd.DataFrame()

    defect_cols = detect_defect_columns(defects_3y)
    if "ç·ä¸å…·åˆæ•°" in defects_3y.columns:
        def_series = defects_3y["ç·ä¸å…·åˆæ•°"]
    else:
        def_series = defects_3y[defect_cols].sum(axis=1) if defect_cols else pd.Series(0, index=defects_3y.index)

    qty_col = "æ•°é‡" if "æ•°é‡" in defects_3y.columns else None
    base = defects_3y.copy()
    base["_defect_total"] = def_series
    base["_qty_total"] = base[qty_col] if qty_col else 0
    base = base[base["å“ç•ª"].isin(target_hinbans)].copy()
    if base.empty:
        return pd.DataFrame(), pd.DataFrame()

    base["æœˆ"] = base[date_col].dt.to_period("M").dt.to_timestamp()
    base["å››åŠæœŸ"] = base[date_col].dt.to_period("Q").dt.to_timestamp()

    monthly = base.groupby(["å“ç•ª", "æœˆ"], as_index=False).agg({"_defect_total": "sum", "_qty_total": "sum"})
    monthly["ä¸è‰¯ç‡"] = monthly.apply(
        lambda r: (r["_defect_total"] / r["_qty_total"]) if r["_qty_total"] else 0.0,
        axis=1,
    )

    quarterly = base.groupby(["å“ç•ª", "å››åŠæœŸ"], as_index=False).agg({"_defect_total": "sum", "_qty_total": "sum"})
    quarterly["ä¸è‰¯ç‡"] = quarterly.apply(
        lambda r: (r["_defect_total"] / r["_qty_total"]) if r["_qty_total"] else 0.0,
        axis=1,
    )

    return monthly, quarterly


def make_auto_comment(monthly: pd.DataFrame, hinban: str) -> str:
    m = monthly[monthly["å“ç•ª"] == hinban].sort_values("æœˆ")
    if len(m) < 3:
        return "éå»ãƒ‡ãƒ¼ã‚¿ãŒå°‘ãªãå‚¾å‘åˆ¤å®šã§ãã¾ã›ã‚“ã€‚"
    last3 = m.tail(3)["ä¸è‰¯ç‡"].tolist()
    if last3[2] > last3[1] > last3[0]:
        return "ç›´è¿‘3ãƒ¶æœˆã§ä¸è‰¯ç‡ãŒå¢—åŠ å‚¾å‘ã§ã™ã€‚è¦å› ã®æ·±æ˜ã‚Šã‚’æ¨å¥¨ã—ã¾ã™ã€‚"
    if last3[2] < last3[1] < last3[0]:
        return "ç›´è¿‘3ãƒ¶æœˆã§ä¸è‰¯ç‡ãŒæ”¹å–„å‚¾å‘ã§ã™ã€‚ç¶™ç¶šç›£è¦–ã—ã¦ãã ã•ã„ã€‚"
    return "ç›´è¿‘æœŸã§ä¸è‰¯ç‡ã¯æ¨ªã°ã„ã§ã™ã€‚é‡ç‚¹ä¸å…·åˆã®å¯¾ç­–çŠ¶æ³ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"


def compute_lot_history(defects_3y: pd.DataFrame, target_hinbans: List[str]) -> Dict[str, List[Dict[str, object]]]:
    """
    éå»3å¹´åˆ†ã®ãƒ­ãƒƒãƒˆå˜ä½æ¨ç§»ã‚’è¿”ã™ã€‚
    è¿”å´å½¢å¼: {å“ç•ª: [{ç”Ÿç”£ãƒ­ãƒƒãƒˆID, æ—¥ä»˜, å·æ©Ÿ, æ•°é‡, ç·ä¸å…·åˆæ•°, ä¸è‰¯ç‡}, ...]}
    """
    if defects_3y.empty or "å“ç•ª" not in defects_3y.columns or "ç”Ÿç”£ãƒ­ãƒƒãƒˆID" not in defects_3y.columns:
        return {}

    date_col = find_date_column(defects_3y)
    defects_3y = normalize_dates(defects_3y, date_col)
    defect_cols = detect_defect_columns(defects_3y)

    base = defects_3y[defects_3y["å“ç•ª"].isin(target_hinbans)].copy()
    if base.empty:
        return {}

    if "ç·ä¸å…·åˆæ•°" in base.columns:
        base["_defect_total"] = base["ç·ä¸å…·åˆæ•°"]
    else:
        base["_defect_total"] = base[defect_cols].sum(axis=1) if defect_cols else 0

    qty_col = "æ•°é‡" if "æ•°é‡" in base.columns else None
    base["_qty_total"] = base[qty_col] if qty_col else 0

    group_keys = ["å“ç•ª", "ç”Ÿç”£ãƒ­ãƒƒãƒˆID"]
    if "å·æ©Ÿ" in base.columns:
        group_keys.append("å·æ©Ÿ")
    if date_col:
        group_keys.append(date_col)

    g = base.groupby(group_keys, as_index=False).agg({"_defect_total": "sum", "_qty_total": "sum"})
    g["ä¸è‰¯ç‡"] = g.apply(
        lambda r: (r["_defect_total"] / r["_qty_total"]) if r["_qty_total"] else 0.0,
        axis=1,
    )
    if date_col:
        g = g.sort_values(date_col)

    history: Dict[str, List[Dict[str, object]]] = {}
    for hinban, sub in g.groupby("å“ç•ª"):
        rows: List[Dict[str, object]] = []
        for _, r in sub.iterrows():
            rows.append({
                "ç”Ÿç”£ãƒ­ãƒƒãƒˆID": str(r["ç”Ÿç”£ãƒ­ãƒƒãƒˆID"]),
                "æ—¥ä»˜": r[date_col].strftime("%Y-%m-%d") if date_col and pd.notna(r[date_col]) else "",
                "å·æ©Ÿ": str(r["å·æ©Ÿ"]) if "å·æ©Ÿ" in r else "",
                "æ•°é‡": float(r["_qty_total"]),
                "ç·ä¸å…·åˆæ•°": float(r["_defect_total"]),
                "ä¸è‰¯ç‡": float(r["ä¸è‰¯ç‡"]),
            })
        history[str(hinban)] = rows
    return history


def build_trend_table_from_history(history_rows: List[Dict[str, object]], limit: int = 20) -> str:
    if not history_rows:
        return "éå»ãƒ­ãƒƒãƒˆãªã—"
    rows = history_rows[-limit:]
    header = "æ—¥ä»˜, ç”Ÿç”£ãƒ­ãƒƒãƒˆID, å·æ©Ÿ, æ•°é‡, ä¸è‰¯æ•°, ä¸è‰¯ç‡"
    lines = [header]
    for r in rows:
        lines.append(
            f"{r.get('æ—¥ä»˜','')}, {r.get('ç”Ÿç”£ãƒ­ãƒƒãƒˆID','')}, {r.get('å·æ©Ÿ','')}, "
            f"{int(r.get('æ•°é‡',0))}, {int(r.get('ç·ä¸å…·åˆæ•°',0))}, {r.get('ä¸è‰¯ç‡',0)*100:.2f}%"
        )
    return "\n".join(lines)


def build_trend_summary_from_history(history_rows: List[Dict[str, object]], recent_limit: int = 20) -> str:
    """
    éå»3å¹´ã®å…¨ä½“è¦ç´„ + ç›´è¿‘æœŸãƒ­ãƒƒãƒˆè¡¨ã‚’è¿”ã™ã€‚
    AIãŒã€Œç›´è¿‘ã ã‘ã€ã¨èª¤è§£ã—ãªã„ã‚ˆã†ã€æœŸé–“ãƒ»ãƒ­ãƒƒãƒˆæ•°ãƒ»å¹´æ¬¡å‚¾å‘ã‚’æ˜ç¤ºã™ã‚‹ã€‚
    """
    if not history_rows:
        return "éå»3å¹´ã®ãƒ­ãƒƒãƒˆãƒ‡ãƒ¼ã‚¿ãªã—"

    # å…¨ä½“æœŸé–“
    dates = [r.get("æ—¥ä»˜") for r in history_rows if r.get("æ—¥ä»˜")]
    start = min(dates) if dates else ""
    end = max(dates) if dates else ""
    lot_count = len(history_rows)

    # å¹´æ¬¡è¦ç´„
    by_year: Dict[str, Dict[str, float]] = {}
    for r in history_rows:
        d = r.get("æ—¥ä»˜") or ""
        y = str(d)[:4] if d else "unknown"
        by_year.setdefault(y, {"qty": 0.0, "ng": 0.0})
        by_year[y]["qty"] += float(r.get("æ•°é‡", 0) or 0)
        by_year[y]["ng"] += float(r.get("ç·ä¸å…·åˆæ•°", 0) or 0)

    year_lines = []
    for y in sorted(by_year.keys()):
        qty = by_year[y]["qty"]
        ng = by_year[y]["ng"]
        rate = (ng / qty * 100) if qty else 0.0
        year_lines.append(f"{y}: æ¤œæŸ»æ•°{int(qty)} / ä¸è‰¯æ•°{int(ng)} / ä¸è‰¯ç‡{rate:.2f}%")

    recent_table = build_trend_table_from_history(history_rows, limit=recent_limit)

    return "\n".join([
        f"ã€éå»3å¹´ã®ãƒ­ãƒƒãƒˆæ¨ç§» è¦ç´„ã€‘",
        f"- æœŸé–“: {start} ã€œ {end}",
        f"- ãƒ­ãƒƒãƒˆæ•°: {lot_count}",
        *[f"- {l}" for l in year_lines],
        "",
        f"ã€ç›´è¿‘æœŸ{recent_limit}ãƒ­ãƒƒãƒˆã®è©³ç´°ã€‘",
        recent_table,
    ])


def build_defect_kind_summary(defects_3y: pd.DataFrame, hinban: str) -> str:
    if defects_3y.empty or "å“ç•ª" not in defects_3y.columns:
        return "ä¸å…·åˆåŒºåˆ†ãƒ‡ãƒ¼ã‚¿ãªã—"
    sub = defects_3y[defects_3y["å“ç•ª"].astype(str) == str(hinban)].copy()
    if sub.empty:
        return "ä¸å…·åˆåŒºåˆ†ãƒ‡ãƒ¼ã‚¿ãªã—"
    defect_cols = detect_defect_columns(sub)
    if not defect_cols:
        return "ä¸å…·åˆåŒºåˆ†ãƒ‡ãƒ¼ã‚¿ãªã—"
    sums = sub[defect_cols].sum().sort_values(ascending=False)
    total = float(sums.sum()) or 1.0
    parts = []
    for k, v in sums.head(6).items():
        if v <= 0:
            continue
        parts.append(f"{k}: {int(v)}ä»¶ ({v/total:.1%})")
    return " / ".join(parts) if parts else "ä¸å…·åˆåŒºåˆ†ãƒ‡ãƒ¼ã‚¿ãªã—"


# -----------------------------
# HTMLãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
# -----------------------------

INLINE_TEMPLATE = r"""
<!DOCTYPE html>
<html lang="ja">
<head>
  <meta charset="utf-8"/>
  <title>Defect Dashboard {{ run_date }}</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <style>
    body { font-family: system-ui, sans-serif; margin: 0; background:#f4f7fb; color:#1a1f36; }
    header { background: radial-gradient(1200px circle at 0% 0%, #5db3ff 0%, #0b5ed7 45%, #083a96 100%); padding: 18px 22px; color: white; position: relative; overflow:hidden; }
    header:after { content:''; position:absolute; inset:-40% -10% auto auto; width:420px; height:420px; background: rgba(255,255,255,0.08); border-radius:50%; transform: rotate(12deg); }
    .header-inner { display:flex; align-items:center; gap:14px; position:relative; z-index:1; }
    .brand-logo { height:44px; width:auto; background: rgba(255,255,255,.9); padding:6px 8px; border-radius:10px; }
    .brand-text { display:flex; flex-direction:column; gap:2px; }
    .brand-title { font-weight: 900; font-size: 20px; letter-spacing: .4px; line-height:1.2; }
    .brand-subtitle { opacity: .95; font-weight:600; font-size:13px; }
    main { padding: 18px 22px; max-width: 1200px; margin: 0 auto; }
    .card { background: white; border-radius: 12px; padding: 16px 18px; box-shadow: 0 1px 4px rgba(16,24,40,.06); margin-bottom: 16px;}
    h2 { margin: 0 0 10px; font-size: 18px; }
    table { width:100%; border-collapse: collapse; font-size: 14px; }
    th, td { padding: 9px 8px; border-bottom: 1px solid #e6eaf2; text-align: right; vertical-align: top; }
    th { text-align: left; background:#f8fafc; position: sticky; top:0; font-weight: 700; color:#344054; }
    tbody tr:nth-child(even):not(.ai-row) { background:#fcfdff; }
    td.left { text-align: left; }
    td.key, td.name, td.customer, td.num { color:#101828; font-weight:700; }
    td.key { font-size:15px; letter-spacing:.2px; }
    td.name { font-size:14px; }
    td.customer { font-size:13.5px; }
    td.machine { font-weight:600; color:#1a1f36; }
    td.num { font-variant-numeric: tabular-nums; }
    .tag-badge { display:inline-flex; align-items:center; justify-content:center; width:20px; height:20px; margin-right:6px; border-radius:6px; background:#ffec99; color:#7f2d00; font-size:13px; font-weight:900; box-shadow: inset 0 0 0 1px #ffd43b; }
    .lot-list {
      margin: 0;
      padding: 6px 10px 6px 22px;
      font-size: 12.5px;
      line-height: 1.5;
      background: #eef4ff;
      border: 1px solid #dbe4ff;
      border-radius: 6px;
    }
    .lot-list li { margin: 2px 0; }
    .lot-tag { font-weight:700; color:#0b5ed7; }
    .lot-metrics { color:#344054; }
    .lot-metrics.red { color:#c92a2a; font-weight:600; }
    /* ã‚µãƒãƒªãƒ†ãƒ¼ãƒ–ãƒ«ã®ãƒ˜ãƒƒãƒ€/ãƒ‡ãƒ¼ã‚¿ä½ç½®ã‚’ä¸€è‡´ã•ã›ã‚‹ï¼ˆæ–°ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆï¼‰ */
    table.summary th:nth-child(1),
    table.summary th:nth-child(2),
    table.summary th:nth-child(3),
    table.summary th:nth-child(7) { text-align: left; }
    table.summary th:nth-child(4),
    table.summary th:nth-child(5),
    table.summary th:nth-child(6) { text-align: right; }
    table.summary td:nth-child(1),
    table.summary td:nth-child(2),
    table.summary td:nth-child(3),
    table.summary td:nth-child(7) { text-align: left; }
    table.summary td:nth-child(4),
    table.summary td:nth-child(5),
    table.summary td:nth-child(6) { text-align: right; }
    .pill { display:inline-block; padding:2px 8px; border-radius:999px; font-weight:600; font-size:12px;}
    .pill.blue { background:#e7f5ff; color:#0b5ed7; }
    .pill.red { background:#ffe3e3; color:#c92a2a; }
    .grid { display:grid; grid-template-columns: 1fr 1fr; gap: 12px; }
    .muted { color:#667085; font-size:12px; }
    .section-header {
      display:flex;
      align-items:center;
      gap:8px;
      padding:8px 10px;
      margin:2px 0 8px;
      border-radius:10px;
      font-weight:800;
      font-size:16px;
      letter-spacing:.2px;
      color:#101828;
      background:#f1f5ff;
      border:1px solid #dbe4ff;
    }
    .section-header .icon { font-size:18px; }
    .section-header.worst { background:#fff4e6; border-color:#ffe8cc; color:#7f2d00; }
    .section-header.normal { background:#eef8f3; border-color:#d3f9d8; color:#0f5132; }
    .section-sub { font-size:11.5px; font-weight:600; color:inherit; opacity:.75; margin-left:auto; }
    .ai-row td { background:#f9fbff; text-align:left; padding:2px 8px; }
    .ai-comment {
      background:#f8fafc;
      border-left:3px solid #0b5ed7;
      padding:4px 10px;
      white-space:pre-line;
      font-size:12.5px;
      line-height:1.55;
      text-align:left;
      border-radius:6px;
      color:#101828;
    }
    .ai-comment ol, .ai-comment ul { margin:4px 0 0 18px; padding:0; }
    .ai-comment li { margin:2px 0; }
    .ai-comment p { margin:0 0 4px; }
    .ai-comment.empty {
      background:#ffffff;
      border-left-color:#d0d5dd;
      color:#667085;
    }
    .ai-title { font-size:12px; font-weight:700; margin:0 0 1px; color:#0b5ed7; letter-spacing:.2px;}
    .ai-meta { font-size:11px; color:#98a2b3; margin-left:6px; font-weight:500; }
    @media (max-width: 768px) {
      main { padding: 12px; }
      table { font-size: 13px; }
      .grid { grid-template-columns: 1fr; }
      .brand-logo { height:36px; }
      .brand-title { font-size:18px; }
    }
    @media (max-width: 640px) {
      table.summary thead { display:none; }
      table.summary, table.summary tbody, table.summary tr { display:block; width:100%; }
      table.summary tr:not(.ai-row) {
        background:#ffffff;
        border:1px solid #e6eaf2;
        border-radius:10px;
        padding:6px 8px;
        margin:0 0 8px 0;
      }
      table.summary td {
        display:flex;
        justify-content:space-between;
        gap:8px;
        padding:4px 0;
        border-bottom:none;
        text-align:right;
      }
      table.summary td::before {
        content: attr(data-label);
        font-weight:600;
        color:#667085;
        flex:0 0 42%;
        text-align:left;
      }
      table.summary td.lot-cell {
        display:block;
        padding-top:6px;
      }
      table.summary td.lot-cell::before {
        display:block;
        margin-bottom:4px;
      }
      .lot-list { width:100%; word-break: break-word; }
      .lot-metrics { word-break: break-word; }
      /* AIã‚³ãƒ¡ãƒ³ãƒˆè¡Œã¯ã‚«ãƒ¼ãƒ‰å¤–ã§å…¨å¹…ãƒ»å·¦å¯„ã› */
      table.summary tr.ai-row { padding:0; margin:0 0 10px 0; }
      table.summary tr.ai-row td {
        display:block;
        padding:4px 0;
        text-align:left;
      }
      table.summary tr.ai-row td::before { content: none; }
      .ai-comment { width:100%; box-sizing:border-box; }
    }
    footer { text-align:center; padding: 12px; color:#98a2b3; font-size:12px; }
  </style>
</head>
<body>
  <header>
    <div class="header-inner">
      <img class="brand-logo" src="{{ logo_data_uri }}" alt="ARAI logo"/>
      <div class="brand-text">
        <div class="brand-title">{{ logo_text }} Defect Dashboard</div>
        <div class="brand-subtitle">æ¤œæŸ»æ—¥: {{ run_date }}</div>
      </div>
    </div>
  </header>
  <main>
    <div class="card">
      {% if worst_today_summary %}
      <div class="section-header worst">
        <span class="icon">âš </span>
        <span>41æœŸãƒ¯ãƒ¼ã‚¹ãƒˆè£½å“ï¼ˆæœ¬æ—¥åˆ†ï¼‰</span>
        <span class="section-sub">é‡ç‚¹ç›£è¦–å¯¾è±¡</span>
      </div>
      <table class="summary">
        <thead>
          <tr>
            <th>å“ç•ª</th>
            <th>å“å</th>
            <th>å®¢å…ˆå</th>
            <th>æ•°é‡åˆè¨ˆ</th>
            <th>ç·ä¸å…·åˆæ•°åˆè¨ˆ</th>
            <th>ä¸è‰¯ç‡åˆè¨ˆ</th>
            <th>ãƒ­ãƒƒãƒˆä¸€è¦§ï¼ˆä¸è‰¯ç‡é«˜ã„é †ï¼‰</th>
          </tr>
        </thead>
        <tbody>
          {% for row in worst_today_summary %}
          <tr>
            <td class="left key" data-label="å“ç•ª"><span class="tag-badge">ğŸ·</span>{{ row["å“ç•ª"] }}</td>
            <td class="left name" data-label="å“å">{{ row.get("å“å","") }}</td>
            <td class="left customer" data-label="å®¢å…ˆå">{{ row.get("å®¢å…ˆå","") }}</td>
            <td class="num" data-label="æ•°é‡åˆè¨ˆ">{{ "{:,.0f}".format(row["æ•°é‡åˆè¨ˆ"]) }}</td>
            <td class="num" data-label="ç·ä¸å…·åˆæ•°åˆè¨ˆ">{{ "{:,.0f}".format(row["ç·ä¸å…·åˆæ•°åˆè¨ˆ"]) }}</td>
            <td>
              {% set rate = row["ä¸è‰¯ç‡åˆè¨ˆ"] %}
              <span class="pill {{ 'blue' if rate == 0 else 'red' }}">{{ "{:.2%}".format(rate) }}</span>
            </td>
            <td class="left lot-cell" data-label="ãƒ­ãƒƒãƒˆä¸€è¦§">
              <ul class="lot-list">
                {% for lot in row["ãƒ­ãƒƒãƒˆä¸€è¦§"] %}
                  {% set lot_has_ng = (lot["ç·ä¸å…·åˆæ•°"]|float) > 0 or (lot["ä¸è‰¯ç‡"]|float) > 0 %}
                  <li>
                    <span class="lot-tag">{{ lot["å·æ©Ÿ"] }}</span>
                    <span class="lot-metrics {{ 'red' if lot_has_ng else '' }}">
                      æ•°é‡{{ "{:,.0f}".format(lot["æ•°é‡"]) }},
                      ä¸è‰¯{{ "{:,.0f}".format(lot["ç·ä¸å…·åˆæ•°"]) }}
                      ({{ "{:.2%}".format(lot["ä¸è‰¯ç‡"]) }})
                      {% if lot["ä¸å…·åˆå†…è¨³"] and lot["ä¸å…·åˆå†…è¨³"] != "-" %}
                        ï¼š{{ lot["ä¸å…·åˆå†…è¨³"] }}
                      {% endif %}
                    </span>
                  </li>
                {% endfor %}
              </ul>
            </td>
          </tr>
          {% set hinban_key = row['å“ç•ª'] | string | trim %}
          {% set has_ai = ai_comments.get(hinban_key) %}
          <tr class="ai-row">
            <td colspan="7">
              <div class="ai-comment {{ 'empty' if not has_ai else '' }}">
                <div class="ai-title">AIåˆ†æã‚³ãƒ¡ãƒ³ãƒˆ{% if not has_ai %}<span class="ai-meta">æœªç”Ÿæˆ</span>{% endif %}</div>
                {% if has_ai %}
                  {{ has_ai }}
                {% else %}
                  {{ ai_status if ai_status else "AIã‚³ãƒ¡ãƒ³ãƒˆã¯ç”Ÿæˆã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ï¼ˆGeminiæœªè¨­å®šï¼ã‚¯ã‚©ãƒ¼ã‚¿è¶…éï¼å¯¾è±¡ãƒ‡ãƒ¼ã‚¿ä¸è¶³ãªã©ï¼‰" }}
                {% endif %}
              </div>
            </td>
          </tr>
          {% endfor %}
        </tbody>
      </table>
      <div style="height:12px"></div>
      {% endif %}

      <div class="section-header normal">
        <span class="icon">ğŸ“‹</span>
        <span>æœ¬æ—¥ã‚µãƒãƒªãƒ¼</span>
        <span class="section-sub">æ¤œæŸ»çµæœä¸€è¦§</span>
      </div>
      <table class="summary">
        <thead>
          <tr>
            <th>å“ç•ª</th>
            <th>å“å</th>
            <th>å®¢å…ˆå</th>
            <th>æ•°é‡åˆè¨ˆ</th>
            <th>ç·ä¸å…·åˆæ•°åˆè¨ˆ</th>
            <th>ä¸è‰¯ç‡åˆè¨ˆ</th>
            <th>ãƒ­ãƒƒãƒˆä¸€è¦§ï¼ˆä¸è‰¯ç‡é«˜ã„é †ï¼‰</th>
          </tr>
        </thead>
        <tbody>
          {% for row in today_summary %}
          <tr>
            <td class="left key" data-label="å“ç•ª"><span class="tag-badge">ğŸ·</span>{{ row["å“ç•ª"] }}</td>
            <td class="left name" data-label="å“å">{{ row.get("å“å","") }}</td>
            <td class="left customer" data-label="å®¢å…ˆå">{{ row.get("å®¢å…ˆå","") }}</td>
            <td class="num" data-label="æ•°é‡åˆè¨ˆ">{{ "{:,.0f}".format(row["æ•°é‡åˆè¨ˆ"]) }}</td>
            <td class="num" data-label="ç·ä¸å…·åˆæ•°åˆè¨ˆ">{{ "{:,.0f}".format(row["ç·ä¸å…·åˆæ•°åˆè¨ˆ"]) }}</td>
            <td>
              {% set rate = row["ä¸è‰¯ç‡åˆè¨ˆ"] %}
              <span class="pill {{ 'blue' if rate == 0 else 'red' }}">{{ "{:.2%}".format(rate) }}</span>
            </td>
            <td class="left lot-cell" data-label="ãƒ­ãƒƒãƒˆä¸€è¦§">
              <ul class="lot-list">
                {% for lot in row["ãƒ­ãƒƒãƒˆä¸€è¦§"] %}
                  {% set lot_has_ng = (lot["ç·ä¸å…·åˆæ•°"]|float) > 0 or (lot["ä¸è‰¯ç‡"]|float) > 0 %}
                  <li>
                    <span class="lot-tag">{{ lot["å·æ©Ÿ"] }}</span>
                    <span class="lot-metrics {{ 'red' if lot_has_ng else '' }}">
                      æ•°é‡{{ "{:,.0f}".format(lot["æ•°é‡"]) }},
                      ä¸è‰¯{{ "{:,.0f}".format(lot["ç·ä¸å…·åˆæ•°"]) }}
                      ({{ "{:.2%}".format(lot["ä¸è‰¯ç‡"]) }})
                      {% if lot["ä¸å…·åˆå†…è¨³"] and lot["ä¸å…·åˆå†…è¨³"] != "-" %}
                        ï¼š{{ lot["ä¸å…·åˆå†…è¨³"] }}
                      {% endif %}
                    </span>
                  </li>
                {% endfor %}
              </ul>
            </td>
          </tr>
          {% set hinban_key = row['å“ç•ª'] | string | trim %}
          {% set has_ai = ai_comments.get(hinban_key) %}
          <tr class="ai-row">
            <td colspan="7">
              <div class="ai-comment {{ 'empty' if not has_ai else '' }}">
                <div class="ai-title">AIåˆ†æã‚³ãƒ¡ãƒ³ãƒˆ{% if not has_ai %}<span class="ai-meta">æœªç”Ÿæˆ</span>{% endif %}</div>
                {% if has_ai %}
                  {{ has_ai }}
                {% else %}
                  {{ ai_status if ai_status else "AIã‚³ãƒ¡ãƒ³ãƒˆã¯ç”Ÿæˆã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ï¼ˆGeminiæœªè¨­å®šï¼ã‚¯ã‚©ãƒ¼ã‚¿è¶…éï¼å¯¾è±¡ãƒ‡ãƒ¼ã‚¿ä¸è¶³ãªã©ï¼‰" }}
                {% endif %}
              </div>
            </td>
          </tr>
          {% endfor %}
        </tbody>
      </table>
      <div class="muted">å¯¾è±¡ãƒ­ãƒƒãƒˆæ•°: {{ today_lot_count }} / ä¸å…·åˆãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {{ today_defect_count }}</div>
    </div>

  </main>
  <footer>Generated by defect_dashboard_generator.py</footer>
</body>
</html>
"""


def load_template(cfg: Config) -> Template:
    if cfg.template_path:
        tpath = Path(cfg.template_path)
        env = Environment(loader=FileSystemLoader(str(tpath.parent)))
        return env.get_template(tpath.name)
    return Environment().from_string(INLINE_TEMPLATE)


# -----------------------------
# ãƒ¡ã‚¤ãƒ³å‡¦ç†
# -----------------------------

def generate_dashboard(run_date: datetime, cfg: Config) -> Path:
    if load_dotenv is not None:
        load_dotenv()
    setup_logging(cfg.output_dir)

    appearance_df = read_access_table(cfg.appearance_db_path, cfg.appearance_table)
    defect_df = read_access_table(cfg.defect_db_path, cfg.defect_table)
    product_master_df = read_product_master(cfg.defect_db_path)

    today_lots_df = extract_today_lots(appearance_df, run_date)
    today_defects_df = join_defects(today_lots_df, defect_df)

    today_summary, defects_breakdown = compute_today_summary(today_lots_df, today_defects_df)

    if not product_master_df.empty and "å“ç•ª" in today_summary.columns:
        pm = product_master_df.rename(
            columns={"è£½å“ç•ªå·": "å“ç•ª", "è£½å“å": "å“å", "å®¢å…ˆå": "å®¢å…ˆå"}
        )
        today_summary = today_summary.merge(pm, on="å“ç•ª", how="left")
    else:
        today_summary["å“å"] = ""
        today_summary["å®¢å…ˆå"] = ""

    defects_3y = filter_last_3years(defect_df, run_date)
    target_hinbans = sorted(today_summary["å“ç•ª"].astype(str).unique().tolist()) if "å“ç•ª" in today_summary.columns else []
    lot_history = compute_lot_history(defects_3y, target_hinbans)

    worst_set = set(FIXED_WORST_41ST_HINBANS)
    if "å“ç•ª" in today_summary.columns:
        mask_worst_today = today_summary["å“ç•ª"].astype(str).isin(worst_set)
        worst_today_summary = today_summary.loc[mask_worst_today].copy()
        normal_today_summary = today_summary.loc[~mask_worst_today].copy()
    else:
        worst_today_summary = pd.DataFrame()
        normal_today_summary = today_summary

    # Geminiã§AIã‚³ãƒ¡ãƒ³ãƒˆç”Ÿæˆï¼ˆå›ºå®šãƒ¯ãƒ¼ã‚¹ãƒˆã¯å°‚ç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã€ãã®ä»–ã¯ä¸€èˆ¬ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼‰
    ai_comments: Dict[str, str] = {}
    ai_status: str = ""
    global _GEMINI_QUOTA_EXCEEDED
    _GEMINI_QUOTA_EXCEEDED = False

    if os.environ.get("GEMINI_API_KEY"):
        try:
            configure_gemini()
            prev_term = get_previous_term_info(run_date.date())

            all_today_hinbans = (
                sorted(set(today_summary["å“ç•ª"].astype(str).tolist()))
                if "å“ç•ª" in today_summary.columns else []
            )

            for hinban in all_today_hinbans:
                hinban = str(hinban).strip()
                today_rows_all = today_summary[today_summary["å“ç•ª"].astype(str) == hinban]
                today_qty = int(today_rows_all["æ•°é‡"].sum()) if "æ•°é‡" in today_rows_all.columns else 0
                today_ng = int(today_rows_all["ç·ä¸å…·åˆæ•°"].sum()) if "ç·ä¸å…·åˆæ•°" in today_rows_all.columns else 0
                part_name = (
                    today_rows_all["å“å"].astype(str).dropna().iloc[0]
                    if "å“å" in today_rows_all.columns and len(today_rows_all) else ""
                )
                customer = (
                    today_rows_all["å®¢å…ˆå"].astype(str).dropna().iloc[0]
                    if "å®¢å…ˆå" in today_rows_all.columns and len(today_rows_all) else ""
                )
                today_rate = (today_ng / today_qty * 100) if today_qty else 0.0
                today_defect_kinds = " / ".join(
                    [s for s in today_rows_all["ä¸å…·åˆå†…è¨³"].astype(str).tolist() if s and s != "-"]
                ) if "ä¸å…·åˆå†…è¨³" in today_rows_all.columns else ""

                history_rows = lot_history.get(hinban, [])
                trend_table_str = build_trend_summary_from_history(history_rows)
                defect_kind_summary_str = build_defect_kind_summary(defects_3y, hinban)

                if hinban in worst_set:
                    info = FIXED_WORST_41ST_INFO.get(hinban, {})
                    prompt = build_worst_part_prompt_for_term(
                        term_info=prev_term,
                        part_number=hinban,
                        part_name=info.get("å“å", part_name),
                        customer=info.get("å®¢å…ˆå", customer),
                        major_defects=info.get("ä¸»ãªä¸å…·åˆ", ""),
                        trend_table=trend_table_str,
                        defect_kind_summary=defect_kind_summary_str,
                        today_qty=today_qty,
                        today_ng=today_ng,
                        today_rate=today_rate,
                        today_defect_kinds=today_defect_kinds,
                    )
                else:
                    prompt = build_general_part_prompt(
                        part_number=hinban,
                        part_name=part_name,
                        customer=customer,
                        trend_table=trend_table_str,
                        defect_kind_summary=defect_kind_summary_str,
                        today_qty=today_qty,
                        today_ng=today_ng,
                        today_rate=today_rate,
                        today_defect_kinds=today_defect_kinds,
                    )

                comment = generate_worst_part_comment(prompt)
                if comment:
                    ai_comments[hinban] = comment
                if _GEMINI_QUOTA_EXCEEDED:
                    ai_status = "Gemini API ã®ã‚¯ã‚©ãƒ¼ã‚¿ä¸Šé™ã«é”ã—ãŸãŸã‚ã€ä»¥é™ã®AIã‚³ãƒ¡ãƒ³ãƒˆç”Ÿæˆã‚’åœæ­¢ã—ã¾ã—ãŸã€‚"
                    break
        except Exception as e:
            ai_status = f"Gemini ã‚³ãƒ¡ãƒ³ãƒˆç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸï¼ˆ{e.__class__.__name__}ï¼‰ã€‚"
            logging.warning("Gemini comment generation skipped: %s", e)
    else:
        ai_status = "Geminiæœªè¨­å®šã®ãŸã‚AIã‚³ãƒ¡ãƒ³ãƒˆã‚’ç”Ÿæˆã§ãã¾ã›ã‚“ã€‚ï¼ˆ.env ã« GEMINI_API_KEY ã‚’è¨­å®šã—ã¦ãã ã•ã„ï¼‰"
        logging.info("GEMINI_API_KEY not set; AI comments disabled.")

    # å“ç•ªå˜ä½ã«ã¾ã¨ã‚ã¦ã€Œãƒ­ãƒƒãƒˆä¸€è¦§ã€ã‚’ä½œã‚‹ï¼ˆä¸è‰¯ç‡é«˜ã„é †ï¼‰
    def group_by_hinban(df: pd.DataFrame) -> List[Dict[str, object]]:
        if df.empty or "å“ç•ª" not in df.columns:
            return []
        rows: List[Dict[str, object]] = []
        for hinban, sub in df.groupby("å“ç•ª"):
            sub_sorted = sub.sort_values("ä¸è‰¯ç‡", ascending=False)
            lot_list: List[Dict[str, object]] = []
            for _, r in sub_sorted.iterrows():
                lot_list.append({
                    "å·æ©Ÿ": str(r.get("å·æ©Ÿ", "")),
                    "æ•°é‡": float(r.get("æ•°é‡", 0)),
                    "ç·ä¸å…·åˆæ•°": float(r.get("ç·ä¸å…·åˆæ•°", 0)),
                    "ä¸è‰¯ç‡": float(r.get("ä¸è‰¯ç‡", 0)),
                    "ä¸å…·åˆå†…è¨³": str(r.get("ä¸å…·åˆå†…è¨³", "-")),
                })
            qty_total = float(sub_sorted.get("æ•°é‡", 0).sum()) if "æ•°é‡" in sub_sorted.columns else 0.0
            ng_total = float(sub_sorted.get("ç·ä¸å…·åˆæ•°", 0).sum()) if "ç·ä¸å…·åˆæ•°" in sub_sorted.columns else 0.0
            rate_total = (ng_total / qty_total) if qty_total else 0.0
            first = sub_sorted.iloc[0]
            rows.append({
                "å“ç•ª": str(hinban),
                "å“å": str(first.get("å“å", "")),
                "å®¢å…ˆå": str(first.get("å®¢å…ˆå", "")),
                "æ•°é‡åˆè¨ˆ": qty_total,
                "ç·ä¸å…·åˆæ•°åˆè¨ˆ": ng_total,
                "ä¸è‰¯ç‡åˆè¨ˆ": rate_total,
                "ãƒ­ãƒƒãƒˆä¸€è¦§": lot_list,
            })
        # å“ç•ªå˜ä½ã®ä¸¦ã³ã‚‚ä¸è‰¯ç‡åˆè¨ˆé«˜ã„é †
        rows.sort(key=lambda x: x.get("ä¸è‰¯ç‡åˆè¨ˆ", 0), reverse=True)
        return rows

    worst_today_grouped = group_by_hinban(worst_today_summary)
    normal_today_grouped = group_by_hinban(normal_today_summary)

    template = load_template(cfg)
    html = template.render(
        run_date=run_date.strftime("%Y-%m-%d"),
        logo_text=cfg.logo_text,
        logo_data_uri=f"data:image/png;base64,{LOGO_BASE64}",
        today_summary=normal_today_grouped,
        worst_today_summary=worst_today_grouped,
        today_lot_count=int(today_lots_df["ç”Ÿç”£ãƒ­ãƒƒãƒˆID"].nunique()),
        today_defect_count=int(len(today_defects_df)),
        breakdown_columns=[],
        breakdown_rows=[],
        ai_comments=ai_comments,
        ai_status=ai_status,
    )

    out_path = Path(cfg.output_dir) / f"defect_dashboard_{run_date:%Y-%m-%d}.html"
    out_path.write_text(html, encoding="utf-8")
    logging.info("dashboard written: %s", out_path)
    return out_path


def parse_args(argv: Optional[Iterable[str]] = None) -> argparse.Namespace:
    p = argparse.ArgumentParser(description="Generate defect dashboard HTML")
    p.add_argument("--run-date", type=str, help="YYYY-MM-DD (default: today)")
    p.add_argument("--config", type=str, help="path to JSON config")
    return p.parse_args(argv)


def main(argv: Optional[Iterable[str]] = None) -> None:
    args = parse_args(argv)
    run_date = datetime.now()
    if args.run_date:
        run_date = datetime.strptime(args.run_date, "%Y-%m-%d")
    cfg = load_config(args.config)
    try:
        generate_dashboard(run_date, cfg)
    except Exception as e:
        logging.exception("failed to generate dashboard: %s", e)
        raise


if __name__ == "__main__":
    main()
